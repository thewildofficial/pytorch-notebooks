{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYfepnZO1LpH29Lx9c8Nc3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thewildofficial/pytorch-notebooks/blob/main/titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZXiO8UnQcgZ6",
        "outputId": "7b749f15-a63b-4b45-ddd1-1be2987fcd1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     PassengerId  Survived  Pclass  \\\n",
              "1              2         1       1   \n",
              "3              4         1       1   \n",
              "6              7         0       1   \n",
              "10            11         1       3   \n",
              "11            12         1       1   \n",
              "..           ...       ...     ...   \n",
              "871          872         1       1   \n",
              "872          873         0       1   \n",
              "879          880         1       1   \n",
              "887          888         1       1   \n",
              "889          890         1       1   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
              "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
              "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
              "..                                                 ...     ...   ...    ...   \n",
              "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
              "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
              "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
              "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
              "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
              "\n",
              "     Parch    Ticket     Fare        Cabin Embarked  \n",
              "1        0  PC 17599  71.2833          C85        C  \n",
              "3        0    113803  53.1000         C123        S  \n",
              "6        0     17463  51.8625          E46        S  \n",
              "10       1   PP 9549  16.7000           G6        S  \n",
              "11       0    113783  26.5500         C103        S  \n",
              "..     ...       ...      ...          ...      ...  \n",
              "871      1     11751  52.5542          D35        S  \n",
              "872      0       695   5.0000  B51 B53 B55        S  \n",
              "879      1     11767  83.1583          C50        C  \n",
              "887      0    112053  30.0000          B42        S  \n",
              "889      0    111369  30.0000         C148        C  \n",
              "\n",
              "[183 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bf16542-7d53-4ed3-b07c-78273d5fbf46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
              "      <td>female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PP 9549</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>G6</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bonnell, Miss. Elizabeth</td>\n",
              "      <td>female</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113783</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>C103</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>872</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11751</td>\n",
              "      <td>52.5542</td>\n",
              "      <td>D35</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>873</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Carlsson, Mr. Frans Olof</td>\n",
              "      <td>male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>695</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>B51 B53 B55</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>880</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
              "      <td>female</td>\n",
              "      <td>56.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11767</td>\n",
              "      <td>83.1583</td>\n",
              "      <td>C50</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>183 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bf16542-7d53-4ed3-b07c-78273d5fbf46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4bf16542-7d53-4ed3-b07c-78273d5fbf46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4bf16542-7d53-4ed3-b07c-78273d5fbf46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Download the Titanic dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "titanic_dataset = pd.read_csv(url).dropna()\n",
        "\n",
        "titanic_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "ZTi5-U9QXpko"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQyzuZmHch4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "CKCtPeOEdNDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "abHabVTL_IUv",
        "outputId": "8919f9ce-2309-4ed3-c9ed-215e3ac3cad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\"Pclass\",\"Sex\",\"Age\",\"Parch\",\"SibSp\",\"Fare\",\"Embarked\"]\n",
        "X = titanic_dataset[features]\n",
        "y = titanic_dataset[\"Survived\"]\n",
        "X['Sex'] = X['Sex'].replace({'male': 0, 'female': 1})\n",
        "X[\"Embarked\"] = X[\"Embarked\"].replace({\"C\": 0, \"S\": 1,\"Q\": 2})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDH335Ii_I4k",
        "outputId": "199e5c5d-1088-47f6-feec-85c08a40972c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-247-56ad83dbe06e>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Sex'] = X['Sex'].replace({'male': 0, 'female': 1})\n",
            "<ipython-input-247-56ad83dbe06e>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[\"Embarked\"] = X[\"Embarked\"].replace({\"C\": 0, \"S\": 1,\"Q\": 2})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "y6Py0KDo_YNE",
        "outputId": "6c837f35-92cc-4532-d7de-807df1afff8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pclass  Sex   Age  Parch  SibSp     Fare  Embarked\n",
              "1         1    1  38.0      0      1  71.2833         0\n",
              "3         1    1  35.0      0      1  53.1000         1\n",
              "6         1    0  54.0      0      0  51.8625         1\n",
              "10        3    1   4.0      1      1  16.7000         1\n",
              "11        1    1  58.0      0      0  26.5500         1\n",
              "..      ...  ...   ...    ...    ...      ...       ...\n",
              "871       1    1  47.0      1      1  52.5542         1\n",
              "872       1    0  33.0      0      0   5.0000         1\n",
              "879       1    1  56.0      1      0  83.1583         0\n",
              "887       1    1  19.0      0      0  30.0000         1\n",
              "889       1    0  26.0      0      0  30.0000         0\n",
              "\n",
              "[183 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-497f784e-c269-4570-93ff-9337baf24ce4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Parch</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>52.5542</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>872</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>83.1583</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>183 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-497f784e-c269-4570-93ff-9337baf24ce4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-497f784e-c269-4570-93ff-9337baf24ce4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-497f784e-c269-4570-93ff-9337baf24ce4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.7,random_state=69)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PNRVauwNA8r-",
        "outputId": "1cffd2d3-990a-41eb-e86e-b3b60e07ada4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pclass  Sex   Age  Parch  SibSp      Fare  Embarked\n",
              "269       1    1  35.0      0      0  135.6333         1\n",
              "430       1    0  28.0      0      0   26.5500         1\n",
              "698       1    0  49.0      1      1  110.8833         0\n",
              "248       1    0  37.0      1      1   52.5542         1\n",
              "262       1    0  52.0      1      1   79.6500         1\n",
              "627       1    1  21.0      0      0   77.9583         1\n",
              "820       1    1  52.0      1      1   93.5000         1\n",
              "625       1    0  61.0      0      0   32.3208         1\n",
              "751       3    0   6.0      1      0   12.4750         1\n",
              "110       1    0  47.0      0      0   52.0000         1\n",
              "556       1    1  48.0      0      1   39.6000         0\n",
              "66        2    1  29.0      0      0   10.5000         1\n",
              "558       1    1  39.0      1      1   79.6500         1\n",
              "327       2    1  36.0      0      0   13.0000         1\n",
              "701       1    0  35.0      0      0   26.2875         1\n",
              "809       1    1  33.0      0      1   53.1000         1\n",
              "462       1    0  47.0      0      0   38.5000         1\n",
              "97        1    0  23.0      1      0   63.3583         0\n",
              "583       1    0  36.0      0      0   40.1250         0\n",
              "456       1    0  65.0      0      0   26.5500         1\n",
              "92        1    0  46.0      0      1   61.1750         1\n",
              "544       1    0  50.0      0      1  106.4250         0\n",
              "742       1    1  21.0      2      2  262.3750         0\n",
              "370       1    0  25.0      0      1   55.4417         0\n",
              "339       1    0  45.0      0      0   35.5000         1\n",
              "716       1    1  38.0      0      0  227.5250         0\n",
              "699       3    0  42.0      0      0    7.6500         1\n",
              "209       1    0  40.0      0      0   31.0000         0\n",
              "724       1    0  27.0      0      1   53.1000         1\n",
              "257       1    1  30.0      0      0   86.5000         1\n",
              "806       1    0  39.0      0      0    0.0000         1\n",
              "879       1    1  56.0      1      0   83.1583         0\n",
              "587       1    0  60.0      1      1   79.2000         0\n",
              "730       1    1  29.0      0      0  211.3375         1\n",
              "230       1    1  35.0      0      1   83.4750         1\n",
              "6         1    0  54.0      0      0   51.8625         1\n",
              "139       1    0  24.0      0      0   79.2000         0\n",
              "394       3    1  24.0      2      0   16.7000         1\n",
              "10        3    1   4.0      1      1   16.7000         1\n",
              "297       1    1   2.0      2      1  151.5500         1\n",
              "369       1    1  24.0      0      0   69.3000         0\n",
              "520       1    1  30.0      0      0   93.5000         1\n",
              "782       1    0  29.0      0      0   30.0000         1\n",
              "690       1    0  31.0      0      1   57.0000         1\n",
              "449       1    0  52.0      0      0   30.5000         1\n",
              "486       1    1  35.0      0      1   90.0000         1\n",
              "224       1    0  38.0      0      1   90.0000         1\n",
              "54        1    0  65.0      1      0   61.9792         0\n",
              "136       1    1  19.0      2      0   26.2833         1\n",
              "273       1    0  37.0      1      0   29.7000         0\n",
              "715       3    0  19.0      0      0    7.6500         1\n",
              "453       1    0  49.0      0      1   89.1042         0\n",
              "523       1    1  44.0      1      0   57.9792         0\n",
              "299       1    1  50.0      1      0  247.5208         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0b47f37-c4c7-41fd-875b-6fa1bb1ddeef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Parch</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>135.6333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>698</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>110.8833</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>52.5542</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79.6500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>77.9583</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>820</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>93.5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32.3208</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>12.4750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>39.6000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79.6500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>701</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.2875</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>33.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38.5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>63.3583</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>583</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40.1250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>61.1750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>106.4250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>262.3750</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>55.4417</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>227.5250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.6500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.0000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86.5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>806</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>56.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>83.1583</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79.2000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>83.4750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>79.2000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>69.3000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93.5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>782</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>690</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>57.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>90.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>90.0000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>61.9792</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>26.2833</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>29.7000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.6500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>89.1042</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>44.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>57.9792</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>247.5208</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0b47f37-c4c7-41fd-875b-6fa1bb1ddeef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0b47f37-c4c7-41fd-875b-6fa1bb1ddeef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0b47f37-c4c7-41fd-875b-6fa1bb1ddeef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to tensors\n",
        "X_train = torch.tensor(X_train.values.astype(np.float32)).to(device)\n",
        "X_test = torch.tensor(X_test.values.astype(np.float32)).to(device)\n",
        "y_train = torch.tensor(y_train.values.astype(np.float32)).to(device)\n",
        "y_test = torch.tensor(y_test.values.astype(np.float32)).to(device)"
      ],
      "metadata": {
        "id": "cjPf4JF0BsSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.to(torch.float32)\n",
        "X_test = X_test.to(torch.float32)\n",
        "y_train = y_train.to(torch.float32)\n",
        "y_test =y_test.to(torch.float32)"
      ],
      "metadata": {
        "id": "9vFx19B8EmUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoWMGf-RGHSe",
        "outputId": "249629e3-a137-40b4-a977-2406b5486c50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1.0000,   1.0000,  17.0000,   0.0000,   1.0000,  57.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  49.0000,   0.0000,   1.0000,  76.7292,   0.0000],\n",
              "        [  1.0000,   1.0000,  18.0000,   0.0000,   1.0000, 227.5250,   0.0000],\n",
              "        [  1.0000,   1.0000,  23.0000,   2.0000,   3.0000, 263.0000,   1.0000],\n",
              "        [  2.0000,   0.0000,   3.0000,   1.0000,   1.0000,  26.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  22.0000,   0.0000,   1.0000,  66.6000,   1.0000],\n",
              "        [  1.0000,   1.0000,  39.0000,   1.0000,   1.0000,  83.1583,   0.0000],\n",
              "        [  1.0000,   1.0000,  33.0000,   0.0000,   1.0000,  90.0000,   2.0000],\n",
              "        [  1.0000,   1.0000,  58.0000,   1.0000,   0.0000, 153.4625,   1.0000],\n",
              "        [  1.0000,   1.0000,  18.0000,   2.0000,   2.0000, 262.3750,   0.0000],\n",
              "        [  2.0000,   1.0000,  24.0000,   0.0000,   0.0000,  13.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  53.0000,   0.0000,   2.0000,  51.4792,   1.0000],\n",
              "        [  2.0000,   0.0000,   2.0000,   1.0000,   1.0000,  26.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  24.0000,   0.0000,   0.0000,  49.5042,   0.0000],\n",
              "        [  1.0000,   1.0000,  30.0000,   0.0000,   0.0000,  56.9292,   0.0000],\n",
              "        [  3.0000,   1.0000,  27.0000,   1.0000,   0.0000,  12.4750,   1.0000],\n",
              "        [  2.0000,   1.0000,   4.0000,   1.0000,   2.0000,  39.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  37.0000,   0.0000,   1.0000,  53.1000,   1.0000],\n",
              "        [  1.0000,   0.0000,  58.0000,   0.0000,   0.0000,  29.7000,   0.0000],\n",
              "        [  1.0000,   0.0000,  80.0000,   0.0000,   0.0000,  30.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  31.0000,   0.0000,   1.0000, 113.2750,   0.0000],\n",
              "        [  1.0000,   1.0000,  44.0000,   0.0000,   0.0000,  27.7208,   0.0000],\n",
              "        [  1.0000,   0.0000,  19.0000,   0.0000,   1.0000,  53.1000,   1.0000],\n",
              "        [  1.0000,   1.0000,  24.0000,   0.0000,   0.0000,  83.1583,   0.0000],\n",
              "        [  1.0000,   1.0000,  15.0000,   1.0000,   0.0000, 211.3375,   1.0000],\n",
              "        [  1.0000,   0.0000,  27.0000,   0.0000,   0.0000,  76.7292,   0.0000],\n",
              "        [  2.0000,   0.0000,  36.0000,   0.0000,   0.0000,  12.8750,   0.0000],\n",
              "        [  2.0000,   1.0000,  57.0000,   0.0000,   0.0000,  10.5000,   1.0000],\n",
              "        [  1.0000,   0.0000,  71.0000,   0.0000,   0.0000,  34.6542,   0.0000],\n",
              "        [  1.0000,   1.0000,  36.0000,   0.0000,   0.0000, 135.6333,   0.0000],\n",
              "        [  1.0000,   1.0000,  19.0000,   0.0000,   0.0000,  30.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  50.0000,   0.0000,   1.0000,  55.9000,   1.0000],\n",
              "        [  1.0000,   1.0000,  36.0000,   2.0000,   0.0000,  71.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  39.0000,   0.0000,   1.0000,  55.9000,   1.0000],\n",
              "        [  1.0000,   0.0000,  49.0000,   0.0000,   1.0000,  56.9292,   0.0000],\n",
              "        [  1.0000,   0.0000,  45.0000,   0.0000,   1.0000,  83.4750,   1.0000],\n",
              "        [  1.0000,   0.0000,  27.0000,   2.0000,   0.0000, 211.5000,   0.0000],\n",
              "        [  1.0000,   0.0000,  32.0000,   0.0000,   0.0000,  30.5000,   0.0000],\n",
              "        [  1.0000,   0.0000,  62.0000,   0.0000,   0.0000,  26.5500,   1.0000],\n",
              "        [  1.0000,   0.0000,  55.0000,   0.0000,   0.0000,  30.5000,   1.0000],\n",
              "        [  2.0000,   1.0000,  32.5000,   0.0000,   0.0000,  13.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  60.0000,   0.0000,   1.0000,  75.2500,   0.0000],\n",
              "        [  1.0000,   0.0000,  31.0000,   0.0000,   0.0000,  50.4958,   1.0000],\n",
              "        [  1.0000,   0.0000,  17.0000,   2.0000,   0.0000, 110.8833,   0.0000],\n",
              "        [  1.0000,   0.0000,  30.0000,   0.0000,   0.0000,  27.7500,   0.0000],\n",
              "        [  1.0000,   0.0000,  26.0000,   0.0000,   0.0000,  30.0000,   0.0000],\n",
              "        [  2.0000,   1.0000,  27.0000,   0.0000,   0.0000,  10.5000,   1.0000],\n",
              "        [  1.0000,   1.0000,  58.0000,   0.0000,   0.0000,  26.5500,   1.0000],\n",
              "        [  1.0000,   0.0000,  35.0000,   0.0000,   0.0000, 512.3292,   0.0000],\n",
              "        [  1.0000,   1.0000,  40.0000,   0.0000,   0.0000, 153.4625,   1.0000],\n",
              "        [  1.0000,   1.0000,  33.0000,   0.0000,   0.0000,  86.5000,   1.0000],\n",
              "        [  1.0000,   0.0000,  36.0000,   1.0000,   0.0000, 512.3292,   0.0000],\n",
              "        [  1.0000,   0.0000,  31.0000,   0.0000,   1.0000,  52.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  18.0000,   0.0000,   1.0000, 108.9000,   0.0000],\n",
              "        [  3.0000,   1.0000,   2.0000,   1.0000,   0.0000,  10.4625,   1.0000],\n",
              "        [  1.0000,   0.0000,  36.0000,   0.0000,   0.0000,  26.3875,   1.0000],\n",
              "        [  1.0000,   1.0000,  54.0000,   0.0000,   1.0000,  78.2667,   0.0000],\n",
              "        [  1.0000,   1.0000,  25.0000,   2.0000,   1.0000, 151.5500,   1.0000],\n",
              "        [  1.0000,   0.0000,  29.0000,   0.0000,   1.0000,  66.6000,   1.0000],\n",
              "        [  1.0000,   0.0000,  47.0000,   0.0000,   0.0000,  34.0208,   1.0000],\n",
              "        [  1.0000,   0.0000,  25.0000,   0.0000,   1.0000,  91.0792,   0.0000],\n",
              "        [  1.0000,   0.0000,   4.0000,   2.0000,   0.0000,  81.8583,   1.0000],\n",
              "        [  1.0000,   0.0000,  51.0000,   0.0000,   0.0000,  26.5500,   1.0000],\n",
              "        [  1.0000,   1.0000,  17.0000,   0.0000,   1.0000, 108.9000,   0.0000],\n",
              "        [  1.0000,   1.0000,  22.0000,   1.0000,   0.0000,  55.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  14.0000,   2.0000,   1.0000, 120.0000,   1.0000],\n",
              "        [  2.0000,   0.0000,   1.0000,   1.0000,   2.0000,  39.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  49.0000,   0.0000,   0.0000,  25.9292,   1.0000],\n",
              "        [  1.0000,   0.0000,  48.0000,   0.0000,   0.0000,  26.5500,   1.0000],\n",
              "        [  1.0000,   0.0000,  21.0000,   1.0000,   0.0000,  77.2875,   1.0000],\n",
              "        [  1.0000,   1.0000,  58.0000,   0.0000,   0.0000, 146.5208,   0.0000],\n",
              "        [  1.0000,   0.0000,  64.0000,   4.0000,   1.0000, 263.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  24.0000,   1.0000,   0.0000, 247.5208,   0.0000],\n",
              "        [  1.0000,   0.0000,  42.0000,   0.0000,   1.0000,  52.5542,   1.0000],\n",
              "        [  1.0000,   0.0000,  45.0000,   0.0000,   0.0000,  26.5500,   1.0000],\n",
              "        [  1.0000,   0.0000,  36.0000,   0.0000,   0.0000,  26.2875,   1.0000],\n",
              "        [  1.0000,   0.0000,  36.0000,   0.0000,   1.0000,  78.8500,   1.0000],\n",
              "        [  1.0000,   1.0000,  24.0000,   0.0000,   0.0000,  69.3000,   0.0000],\n",
              "        [  3.0000,   1.0000,  29.0000,   1.0000,   1.0000,  10.4625,   1.0000],\n",
              "        [  1.0000,   1.0000,  23.0000,   0.0000,   1.0000, 113.2750,   0.0000],\n",
              "        [  1.0000,   0.0000,  36.0000,   2.0000,   1.0000, 120.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  63.0000,   0.0000,   1.0000,  77.9583,   1.0000],\n",
              "        [  1.0000,   0.0000,  56.0000,   0.0000,   0.0000,  35.5000,   0.0000],\n",
              "        [  1.0000,   1.0000,  38.0000,   0.0000,   1.0000,  71.2833,   0.0000],\n",
              "        [  1.0000,   1.0000,  43.0000,   1.0000,   0.0000, 211.3375,   1.0000],\n",
              "        [  2.0000,   1.0000,  23.0000,   0.0000,   0.0000,  13.7917,   0.0000],\n",
              "        [  1.0000,   1.0000,  16.0000,   0.0000,   0.0000,  86.5000,   1.0000],\n",
              "        [  2.0000,   1.0000,  34.0000,   0.0000,   0.0000,  10.5000,   1.0000],\n",
              "        [  1.0000,   0.0000,  48.0000,   0.0000,   1.0000,  52.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  40.0000,   1.0000,   1.0000, 134.5000,   0.0000],\n",
              "        [  1.0000,   0.0000,  61.0000,   0.0000,   0.0000,  33.5000,   1.0000],\n",
              "        [  1.0000,   1.0000,  36.0000,   2.0000,   1.0000, 120.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  33.0000,   0.0000,   0.0000,   5.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  38.0000,   1.0000,   0.0000, 153.4625,   1.0000],\n",
              "        [  1.0000,   0.0000,  56.0000,   0.0000,   0.0000,  30.6958,   0.0000],\n",
              "        [  1.0000,   0.0000,  47.0000,   0.0000,   0.0000,  25.5875,   1.0000],\n",
              "        [  1.0000,   1.0000,  19.0000,   0.0000,   1.0000,  91.0792,   0.0000],\n",
              "        [  1.0000,   0.0000,  46.0000,   0.0000,   0.0000,  79.2000,   0.0000],\n",
              "        [  1.0000,   1.0000,  22.0000,   2.0000,   0.0000,  49.5000,   0.0000],\n",
              "        [  1.0000,   1.0000,  31.0000,   2.0000,   0.0000, 164.8667,   1.0000],\n",
              "        [  1.0000,   1.0000,  32.0000,   0.0000,   0.0000,  76.2917,   0.0000],\n",
              "        [  1.0000,   1.0000,  16.0000,   1.0000,   0.0000,  57.9792,   0.0000],\n",
              "        [  1.0000,   1.0000,  39.0000,   1.0000,   1.0000, 110.8833,   0.0000],\n",
              "        [  2.0000,   0.0000,  36.5000,   2.0000,   0.0000,  26.0000,   1.0000],\n",
              "        [  2.0000,   0.0000,  34.0000,   0.0000,   0.0000,  13.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  45.5000,   0.0000,   0.0000,  28.5000,   1.0000],\n",
              "        [  1.0000,   1.0000,  24.0000,   2.0000,   3.0000, 263.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  28.0000,   0.0000,   0.0000,  35.5000,   1.0000],\n",
              "        [  3.0000,   0.0000,  25.0000,   0.0000,   0.0000,   7.6500,   1.0000],\n",
              "        [  1.0000,   1.0000,  50.0000,   0.0000,   0.0000,  28.7125,   0.0000],\n",
              "        [  1.0000,   1.0000,  35.0000,   0.0000,   1.0000,  53.1000,   1.0000],\n",
              "        [  1.0000,   0.0000,  70.0000,   1.0000,   1.0000,  71.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  52.0000,   0.0000,   1.0000,  78.2667,   0.0000],\n",
              "        [  1.0000,   0.0000,  54.0000,   1.0000,   0.0000,  77.2875,   1.0000],\n",
              "        [  1.0000,   0.0000,  42.0000,   0.0000,   0.0000,  26.2875,   1.0000],\n",
              "        [  1.0000,   0.0000,  58.0000,   2.0000,   0.0000, 113.2750,   0.0000],\n",
              "        [  1.0000,   0.0000,   0.9200,   2.0000,   1.0000, 151.5500,   1.0000],\n",
              "        [  3.0000,   0.0000,  32.0000,   0.0000,   0.0000,   8.0500,   1.0000],\n",
              "        [  1.0000,   1.0000,  18.0000,   2.0000,   0.0000,  79.6500,   1.0000],\n",
              "        [  1.0000,   0.0000,  48.0000,   0.0000,   1.0000,  76.7292,   0.0000],\n",
              "        [  1.0000,   1.0000,  48.0000,   0.0000,   0.0000,  25.9292,   1.0000],\n",
              "        [  1.0000,   1.0000,  41.0000,   0.0000,   0.0000, 134.5000,   0.0000],\n",
              "        [  1.0000,   0.0000,  11.0000,   2.0000,   1.0000, 120.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  19.0000,   2.0000,   3.0000, 263.0000,   1.0000],\n",
              "        [  1.0000,   0.0000,  40.0000,   0.0000,   0.0000,   0.0000,   1.0000],\n",
              "        [  1.0000,   1.0000,  51.0000,   0.0000,   1.0000,  77.9583,   1.0000],\n",
              "        [  1.0000,   0.0000,  44.0000,   0.0000,   2.0000,  90.0000,   2.0000],\n",
              "        [  1.0000,   1.0000,  16.0000,   1.0000,   0.0000,  39.4000,   1.0000],\n",
              "        [  1.0000,   1.0000,  47.0000,   1.0000,   1.0000,  52.5542,   1.0000]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(7, 10),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(10,10),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(10, 1),  # Single output unit\n",
        "    torch.nn.Sigmoid()  # Apply sigmoid activation\n",
        ")"
      ],
      "metadata": {
        "id": "LgtuprsZBthh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access and check the data type of the weights\n",
        "for name, param in model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "        print(f\"Weight name: {name}\")\n",
        "        print(f\"Weight data type: {param.dtype}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7u7IyBQH6sX",
        "outputId": "4f9a536f-591f-4c99-bf3d-0410ef66b3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight name: 0.weight\n",
            "Weight data type: torch.float32\n",
            "Weight name: 2.weight\n",
            "Weight data type: torch.float32\n",
            "Weight name: 4.weight\n",
            "Weight data type: torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "model = model.to(device)\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "# calculate accuracy\n",
        "def accuracy_fn(y_true,y_pred):\n",
        "  correct = torch.eq(y_true,y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) * 100  \n",
        "  return acc"
      ],
      "metadata": {
        "id": "QFlx9ySvC3kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoches =  200\n",
        "for epoch in range(epoches):\n",
        "  preds = model.forward(X_train).flatten()\n",
        "  loss = loss_fn(preds, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(f\"Epoch [{epoch+1}/{epoches}], Loss: {loss.item():.4f}, Accuracy: {accuracy_fn(y_train,preds.round())}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yRGO9zLDl-L",
        "outputId": "8116d23e-06a7-49b1-fbb3-196aec92228d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/200], Loss: 0.7894, Accuracy: 64.81481481481481%\n",
            "Epoch [2/200], Loss: 0.7399, Accuracy: 64.81481481481481%\n",
            "Epoch [3/200], Loss: 0.6998, Accuracy: 64.81481481481481%\n",
            "Epoch [4/200], Loss: 0.6729, Accuracy: 64.81481481481481%\n",
            "Epoch [5/200], Loss: 0.6565, Accuracy: 64.81481481481481%\n",
            "Epoch [6/200], Loss: 0.6490, Accuracy: 64.81481481481481%\n",
            "Epoch [7/200], Loss: 0.6458, Accuracy: 64.81481481481481%\n",
            "Epoch [8/200], Loss: 0.6416, Accuracy: 64.81481481481481%\n",
            "Epoch [9/200], Loss: 0.6373, Accuracy: 64.81481481481481%\n",
            "Epoch [10/200], Loss: 0.6309, Accuracy: 64.81481481481481%\n",
            "Epoch [11/200], Loss: 0.6230, Accuracy: 64.81481481481481%\n",
            "Epoch [12/200], Loss: 0.6192, Accuracy: 64.81481481481481%\n",
            "Epoch [13/200], Loss: 0.6168, Accuracy: 64.81481481481481%\n",
            "Epoch [14/200], Loss: 0.6135, Accuracy: 64.81481481481481%\n",
            "Epoch [15/200], Loss: 0.6083, Accuracy: 64.81481481481481%\n",
            "Epoch [16/200], Loss: 0.6025, Accuracy: 66.66666666666666%\n",
            "Epoch [17/200], Loss: 0.5978, Accuracy: 72.22222222222221%\n",
            "Epoch [18/200], Loss: 0.5946, Accuracy: 68.51851851851852%\n",
            "Epoch [19/200], Loss: 0.5923, Accuracy: 66.66666666666666%\n",
            "Epoch [20/200], Loss: 0.5905, Accuracy: 68.51851851851852%\n",
            "Epoch [21/200], Loss: 0.5879, Accuracy: 68.51851851851852%\n",
            "Epoch [22/200], Loss: 0.5849, Accuracy: 68.51851851851852%\n",
            "Epoch [23/200], Loss: 0.5821, Accuracy: 68.51851851851852%\n",
            "Epoch [24/200], Loss: 0.5802, Accuracy: 68.51851851851852%\n",
            "Epoch [25/200], Loss: 0.5791, Accuracy: 68.51851851851852%\n",
            "Epoch [26/200], Loss: 0.5783, Accuracy: 68.51851851851852%\n",
            "Epoch [27/200], Loss: 0.5772, Accuracy: 70.37037037037037%\n",
            "Epoch [28/200], Loss: 0.5757, Accuracy: 70.37037037037037%\n",
            "Epoch [29/200], Loss: 0.5742, Accuracy: 70.37037037037037%\n",
            "Epoch [30/200], Loss: 0.5727, Accuracy: 70.37037037037037%\n",
            "Epoch [31/200], Loss: 0.5712, Accuracy: 72.22222222222221%\n",
            "Epoch [32/200], Loss: 0.5695, Accuracy: 72.22222222222221%\n",
            "Epoch [33/200], Loss: 0.5674, Accuracy: 72.22222222222221%\n",
            "Epoch [34/200], Loss: 0.5652, Accuracy: 72.22222222222221%\n",
            "Epoch [35/200], Loss: 0.5630, Accuracy: 70.37037037037037%\n",
            "Epoch [36/200], Loss: 0.5612, Accuracy: 70.37037037037037%\n",
            "Epoch [37/200], Loss: 0.5593, Accuracy: 70.37037037037037%\n",
            "Epoch [38/200], Loss: 0.5574, Accuracy: 70.37037037037037%\n",
            "Epoch [39/200], Loss: 0.5556, Accuracy: 70.37037037037037%\n",
            "Epoch [40/200], Loss: 0.5540, Accuracy: 70.37037037037037%\n",
            "Epoch [41/200], Loss: 0.5525, Accuracy: 70.37037037037037%\n",
            "Epoch [42/200], Loss: 0.5507, Accuracy: 70.37037037037037%\n",
            "Epoch [43/200], Loss: 0.5489, Accuracy: 70.37037037037037%\n",
            "Epoch [44/200], Loss: 0.5470, Accuracy: 70.37037037037037%\n",
            "Epoch [45/200], Loss: 0.5450, Accuracy: 70.37037037037037%\n",
            "Epoch [46/200], Loss: 0.5429, Accuracy: 70.37037037037037%\n",
            "Epoch [47/200], Loss: 0.5406, Accuracy: 70.37037037037037%\n",
            "Epoch [48/200], Loss: 0.5384, Accuracy: 72.22222222222221%\n",
            "Epoch [49/200], Loss: 0.5362, Accuracy: 72.22222222222221%\n",
            "Epoch [50/200], Loss: 0.5343, Accuracy: 72.22222222222221%\n",
            "Epoch [51/200], Loss: 0.5325, Accuracy: 72.22222222222221%\n",
            "Epoch [52/200], Loss: 0.5307, Accuracy: 72.22222222222221%\n",
            "Epoch [53/200], Loss: 0.5287, Accuracy: 72.22222222222221%\n",
            "Epoch [54/200], Loss: 0.5266, Accuracy: 74.07407407407408%\n",
            "Epoch [55/200], Loss: 0.5244, Accuracy: 74.07407407407408%\n",
            "Epoch [56/200], Loss: 0.5231, Accuracy: 74.07407407407408%\n",
            "Epoch [57/200], Loss: 0.5203, Accuracy: 74.07407407407408%\n",
            "Epoch [58/200], Loss: 0.5184, Accuracy: 72.22222222222221%\n",
            "Epoch [59/200], Loss: 0.5166, Accuracy: 72.22222222222221%\n",
            "Epoch [60/200], Loss: 0.5147, Accuracy: 72.22222222222221%\n",
            "Epoch [61/200], Loss: 0.5127, Accuracy: 74.07407407407408%\n",
            "Epoch [62/200], Loss: 0.5106, Accuracy: 74.07407407407408%\n",
            "Epoch [63/200], Loss: 0.5086, Accuracy: 74.07407407407408%\n",
            "Epoch [64/200], Loss: 0.5065, Accuracy: 74.07407407407408%\n",
            "Epoch [65/200], Loss: 0.5045, Accuracy: 74.07407407407408%\n",
            "Epoch [66/200], Loss: 0.5026, Accuracy: 75.92592592592592%\n",
            "Epoch [67/200], Loss: 0.5007, Accuracy: 74.07407407407408%\n",
            "Epoch [68/200], Loss: 0.4988, Accuracy: 74.07407407407408%\n",
            "Epoch [69/200], Loss: 0.4969, Accuracy: 75.92592592592592%\n",
            "Epoch [70/200], Loss: 0.4949, Accuracy: 75.92592592592592%\n",
            "Epoch [71/200], Loss: 0.4931, Accuracy: 77.77777777777779%\n",
            "Epoch [72/200], Loss: 0.4914, Accuracy: 77.77777777777779%\n",
            "Epoch [73/200], Loss: 0.4897, Accuracy: 77.77777777777779%\n",
            "Epoch [74/200], Loss: 0.4880, Accuracy: 77.77777777777779%\n",
            "Epoch [75/200], Loss: 0.4864, Accuracy: 77.77777777777779%\n",
            "Epoch [76/200], Loss: 0.4850, Accuracy: 75.92592592592592%\n",
            "Epoch [77/200], Loss: 0.4835, Accuracy: 75.92592592592592%\n",
            "Epoch [78/200], Loss: 0.4820, Accuracy: 75.92592592592592%\n",
            "Epoch [79/200], Loss: 0.4804, Accuracy: 75.92592592592592%\n",
            "Epoch [80/200], Loss: 0.4788, Accuracy: 75.92592592592592%\n",
            "Epoch [81/200], Loss: 0.4772, Accuracy: 75.92592592592592%\n",
            "Epoch [82/200], Loss: 0.4760, Accuracy: 75.92592592592592%\n",
            "Epoch [83/200], Loss: 0.4745, Accuracy: 75.92592592592592%\n",
            "Epoch [84/200], Loss: 0.4731, Accuracy: 75.92592592592592%\n",
            "Epoch [85/200], Loss: 0.4718, Accuracy: 75.92592592592592%\n",
            "Epoch [86/200], Loss: 0.4705, Accuracy: 75.92592592592592%\n",
            "Epoch [87/200], Loss: 0.4692, Accuracy: 75.92592592592592%\n",
            "Epoch [88/200], Loss: 0.4678, Accuracy: 75.92592592592592%\n",
            "Epoch [89/200], Loss: 0.4665, Accuracy: 77.77777777777779%\n",
            "Epoch [90/200], Loss: 0.4651, Accuracy: 77.77777777777779%\n",
            "Epoch [91/200], Loss: 0.4638, Accuracy: 77.77777777777779%\n",
            "Epoch [92/200], Loss: 0.4618, Accuracy: 77.77777777777779%\n",
            "Epoch [93/200], Loss: 0.4594, Accuracy: 77.77777777777779%\n",
            "Epoch [94/200], Loss: 0.4568, Accuracy: 77.77777777777779%\n",
            "Epoch [95/200], Loss: 0.4540, Accuracy: 77.77777777777779%\n",
            "Epoch [96/200], Loss: 0.4517, Accuracy: 77.77777777777779%\n",
            "Epoch [97/200], Loss: 0.4494, Accuracy: 77.77777777777779%\n",
            "Epoch [98/200], Loss: 0.4473, Accuracy: 77.77777777777779%\n",
            "Epoch [99/200], Loss: 0.4454, Accuracy: 77.77777777777779%\n",
            "Epoch [100/200], Loss: 0.4435, Accuracy: 77.77777777777779%\n",
            "Epoch [101/200], Loss: 0.4417, Accuracy: 77.77777777777779%\n",
            "Epoch [102/200], Loss: 0.4404, Accuracy: 77.77777777777779%\n",
            "Epoch [103/200], Loss: 0.4385, Accuracy: 77.77777777777779%\n",
            "Epoch [104/200], Loss: 0.4368, Accuracy: 77.77777777777779%\n",
            "Epoch [105/200], Loss: 0.4350, Accuracy: 77.77777777777779%\n",
            "Epoch [106/200], Loss: 0.4333, Accuracy: 77.77777777777779%\n",
            "Epoch [107/200], Loss: 0.4317, Accuracy: 77.77777777777779%\n",
            "Epoch [108/200], Loss: 0.4299, Accuracy: 77.77777777777779%\n",
            "Epoch [109/200], Loss: 0.4281, Accuracy: 79.62962962962963%\n",
            "Epoch [110/200], Loss: 0.4263, Accuracy: 79.62962962962963%\n",
            "Epoch [111/200], Loss: 0.4247, Accuracy: 79.62962962962963%\n",
            "Epoch [112/200], Loss: 0.4230, Accuracy: 77.77777777777779%\n",
            "Epoch [113/200], Loss: 0.4214, Accuracy: 79.62962962962963%\n",
            "Epoch [114/200], Loss: 0.4197, Accuracy: 77.77777777777779%\n",
            "Epoch [115/200], Loss: 0.4181, Accuracy: 77.77777777777779%\n",
            "Epoch [116/200], Loss: 0.4163, Accuracy: 79.62962962962963%\n",
            "Epoch [117/200], Loss: 0.4147, Accuracy: 77.77777777777779%\n",
            "Epoch [118/200], Loss: 0.4132, Accuracy: 79.62962962962963%\n",
            "Epoch [119/200], Loss: 0.4117, Accuracy: 77.77777777777779%\n",
            "Epoch [120/200], Loss: 0.4104, Accuracy: 79.62962962962963%\n",
            "Epoch [121/200], Loss: 0.4096, Accuracy: 74.07407407407408%\n",
            "Epoch [122/200], Loss: 0.4093, Accuracy: 81.48148148148148%\n",
            "Epoch [123/200], Loss: 0.4065, Accuracy: 75.92592592592592%\n",
            "Epoch [124/200], Loss: 0.4036, Accuracy: 79.62962962962963%\n",
            "Epoch [125/200], Loss: 0.4030, Accuracy: 81.48148148148148%\n",
            "Epoch [126/200], Loss: 0.4030, Accuracy: 74.07407407407408%\n",
            "Epoch [127/200], Loss: 0.4011, Accuracy: 81.48148148148148%\n",
            "Epoch [128/200], Loss: 0.3984, Accuracy: 77.77777777777779%\n",
            "Epoch [129/200], Loss: 0.3980, Accuracy: 75.92592592592592%\n",
            "Epoch [130/200], Loss: 0.3977, Accuracy: 81.48148148148148%\n",
            "Epoch [131/200], Loss: 0.3946, Accuracy: 77.77777777777779%\n",
            "Epoch [132/200], Loss: 0.3937, Accuracy: 77.77777777777779%\n",
            "Epoch [133/200], Loss: 0.3935, Accuracy: 81.48148148148148%\n",
            "Epoch [134/200], Loss: 0.3909, Accuracy: 77.77777777777779%\n",
            "Epoch [135/200], Loss: 0.3897, Accuracy: 77.77777777777779%\n",
            "Epoch [136/200], Loss: 0.3894, Accuracy: 81.48148148148148%\n",
            "Epoch [137/200], Loss: 0.3872, Accuracy: 77.77777777777779%\n",
            "Epoch [138/200], Loss: 0.3857, Accuracy: 77.77777777777779%\n",
            "Epoch [139/200], Loss: 0.3852, Accuracy: 81.48148148148148%\n",
            "Epoch [140/200], Loss: 0.3835, Accuracy: 77.77777777777779%\n",
            "Epoch [141/200], Loss: 0.3818, Accuracy: 77.77777777777779%\n",
            "Epoch [142/200], Loss: 0.3810, Accuracy: 79.62962962962963%\n",
            "Epoch [143/200], Loss: 0.3798, Accuracy: 75.92592592592592%\n",
            "Epoch [144/200], Loss: 0.3781, Accuracy: 77.77777777777779%\n",
            "Epoch [145/200], Loss: 0.3769, Accuracy: 77.77777777777779%\n",
            "Epoch [146/200], Loss: 0.3759, Accuracy: 75.92592592592592%\n",
            "Epoch [147/200], Loss: 0.3749, Accuracy: 79.62962962962963%\n",
            "Epoch [148/200], Loss: 0.3731, Accuracy: 77.77777777777779%\n",
            "Epoch [149/200], Loss: 0.3716, Accuracy: 77.77777777777779%\n",
            "Epoch [150/200], Loss: 0.3704, Accuracy: 77.77777777777779%\n",
            "Epoch [151/200], Loss: 0.3681, Accuracy: 75.92592592592592%\n",
            "Epoch [152/200], Loss: 0.3578, Accuracy: 77.77777777777779%\n",
            "Epoch [153/200], Loss: 0.3571, Accuracy: 77.77777777777779%\n",
            "Epoch [154/200], Loss: 0.3980, Accuracy: 85.18518518518519%\n",
            "Epoch [155/200], Loss: 0.4197, Accuracy: 81.48148148148148%\n",
            "Epoch [156/200], Loss: 0.3885, Accuracy: 81.48148148148148%\n",
            "Epoch [157/200], Loss: 0.3748, Accuracy: 81.48148148148148%\n",
            "Epoch [158/200], Loss: 0.3773, Accuracy: 83.33333333333334%\n",
            "Epoch [159/200], Loss: 0.3618, Accuracy: 79.62962962962963%\n",
            "Epoch [160/200], Loss: 0.3880, Accuracy: 81.48148148148148%\n",
            "Epoch [161/200], Loss: 0.3520, Accuracy: 77.77777777777779%\n",
            "Epoch [162/200], Loss: 0.3680, Accuracy: 83.33333333333334%\n",
            "Epoch [163/200], Loss: 0.3551, Accuracy: 81.48148148148148%\n",
            "Epoch [164/200], Loss: 0.3490, Accuracy: 77.77777777777779%\n",
            "Epoch [165/200], Loss: 0.3630, Accuracy: 81.48148148148148%\n",
            "Epoch [166/200], Loss: 0.3420, Accuracy: 77.77777777777779%\n",
            "Epoch [167/200], Loss: 0.3516, Accuracy: 81.48148148148148%\n",
            "Epoch [168/200], Loss: 0.3424, Accuracy: 79.62962962962963%\n",
            "Epoch [169/200], Loss: 0.3399, Accuracy: 79.62962962962963%\n",
            "Epoch [170/200], Loss: 0.3447, Accuracy: 81.48148148148148%\n",
            "Epoch [171/200], Loss: 0.3320, Accuracy: 77.77777777777779%\n",
            "Epoch [172/200], Loss: 0.3402, Accuracy: 79.62962962962963%\n",
            "Epoch [173/200], Loss: 0.3326, Accuracy: 79.62962962962963%\n",
            "Epoch [174/200], Loss: 0.3328, Accuracy: 77.77777777777779%\n",
            "Epoch [175/200], Loss: 0.3355, Accuracy: 79.62962962962963%\n",
            "Epoch [176/200], Loss: 0.3286, Accuracy: 77.77777777777779%\n",
            "Epoch [177/200], Loss: 0.3319, Accuracy: 79.62962962962963%\n",
            "Epoch [178/200], Loss: 0.3292, Accuracy: 79.62962962962963%\n",
            "Epoch [179/200], Loss: 0.3266, Accuracy: 77.77777777777779%\n",
            "Epoch [180/200], Loss: 0.3286, Accuracy: 77.77777777777779%\n",
            "Epoch [181/200], Loss: 0.3239, Accuracy: 79.62962962962963%\n",
            "Epoch [182/200], Loss: 0.3242, Accuracy: 79.62962962962963%\n",
            "Epoch [183/200], Loss: 0.3233, Accuracy: 79.62962962962963%\n",
            "Epoch [184/200], Loss: 0.3206, Accuracy: 79.62962962962963%\n",
            "Epoch [185/200], Loss: 0.3218, Accuracy: 77.77777777777779%\n",
            "Epoch [186/200], Loss: 0.3191, Accuracy: 77.77777777777779%\n",
            "Epoch [187/200], Loss: 0.3193, Accuracy: 79.62962962962963%\n",
            "Epoch [188/200], Loss: 0.3183, Accuracy: 79.62962962962963%\n",
            "Epoch [189/200], Loss: 0.3167, Accuracy: 77.77777777777779%\n",
            "Epoch [190/200], Loss: 0.3170, Accuracy: 77.77777777777779%\n",
            "Epoch [191/200], Loss: 0.3148, Accuracy: 79.62962962962963%\n",
            "Epoch [192/200], Loss: 0.3150, Accuracy: 79.62962962962963%\n",
            "Epoch [193/200], Loss: 0.3134, Accuracy: 79.62962962962963%\n",
            "Epoch [194/200], Loss: 0.3125, Accuracy: 79.62962962962963%\n",
            "Epoch [195/200], Loss: 0.3119, Accuracy: 79.62962962962963%\n",
            "Epoch [196/200], Loss: 0.3110, Accuracy: 79.62962962962963%\n",
            "Epoch [197/200], Loss: 0.3108, Accuracy: 79.62962962962963%\n",
            "Epoch [198/200], Loss: 0.3097, Accuracy: 79.62962962962963%\n",
            "Epoch [199/200], Loss: 0.3093, Accuracy: 79.62962962962963%\n",
            "Epoch [200/200], Loss: 0.3081, Accuracy: 79.62962962962963%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpq9GwpqNdOS",
        "outputId": "423fbbda-17ad-4872-af97-d061856c0005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9555, 0.5701, 0.6385, 0.8428, 0.6272, 0.9827, 0.9740, 0.1287, 0.9554,\n",
              "        0.2223, 0.9494, 0.8305, 0.9906, 0.7006, 0.4655, 0.9881, 0.2770, 0.7520,\n",
              "        0.3368, 0.0422, 0.5765, 0.4554, 0.9988, 0.8498, 0.3097, 0.9439, 0.0604,\n",
              "        0.3380, 0.8661, 0.9650, 0.0413, 0.8141, 0.3876, 0.9787, 0.9873, 0.1717,\n",
              "        0.6060, 0.9881, 0.9991, 0.0059, 0.9693, 0.9658, 0.5462, 0.8243, 0.2656,\n",
              "        0.9876, 0.7454, 0.1156, 0.9952, 0.4909, 0.5319, 0.4614, 0.9163, 0.9268],\n",
              "       device='cuda:0', grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_preds = model.forward(X_test).flatten()\n",
        "  accuracy = accuracy_fn(y_test,y_preds.round())\n",
        "  \n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54ZFdU7HDsOa",
        "outputId": "33cbb749-fda9-4c45-8e2c-8d1c1bca76f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72.09302325581395"
            ]
          },
          "metadata": {},
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2oa6Z38YKc0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHATGPT GENERATED MODEL"
      ],
      "metadata": {
        "id": "CotOk3r0MzGt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM9l1jYKeFPD",
        "outputId": "abd399bd-83fb-4a1d-9f81-c13c0c9761c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300, Loss: 0.7378746747970581\n",
            "Epoch 2/300, Loss: 0.7157214164733887\n",
            "Epoch 3/300, Loss: 0.6968382239341736\n",
            "Epoch 4/300, Loss: 0.6790674805641175\n",
            "Epoch 5/300, Loss: 0.6619456768035888\n",
            "Epoch 6/300, Loss: 0.6502362370491028\n",
            "Epoch 7/300, Loss: 0.6360358238220215\n",
            "Epoch 8/300, Loss: 0.6261618256568908\n",
            "Epoch 9/300, Loss: 0.6157841086387634\n",
            "Epoch 10/300, Loss: 0.6103423476219177\n",
            "Epoch 11/300, Loss: 0.6050651669502258\n",
            "Epoch 12/300, Loss: 0.5881236076354981\n",
            "Epoch 13/300, Loss: 0.5904579043388367\n",
            "Epoch 14/300, Loss: 0.5818428993225098\n",
            "Epoch 15/300, Loss: 0.5782539665699005\n",
            "Epoch 16/300, Loss: 0.5623189091682435\n",
            "Epoch 17/300, Loss: 0.5514383554458618\n",
            "Epoch 18/300, Loss: 0.5522697567939758\n",
            "Epoch 19/300, Loss: 0.5492250084877014\n",
            "Epoch 20/300, Loss: 0.5390266537666321\n",
            "Epoch 21/300, Loss: 0.5297828018665314\n",
            "Epoch 22/300, Loss: 0.5220447540283203\n",
            "Epoch 23/300, Loss: 0.5173019349575043\n",
            "Epoch 24/300, Loss: 0.5204618513584137\n",
            "Epoch 25/300, Loss: 0.5148296594619751\n",
            "Epoch 26/300, Loss: 0.5012830197811127\n",
            "Epoch 27/300, Loss: 0.50628941655159\n",
            "Epoch 28/300, Loss: 0.4969994068145752\n",
            "Epoch 29/300, Loss: 0.49249826073646547\n",
            "Epoch 30/300, Loss: 0.49150708317756653\n",
            "Epoch 31/300, Loss: 0.47248672842979433\n",
            "Epoch 32/300, Loss: 0.47150803208351133\n",
            "Epoch 33/300, Loss: 0.4739315927028656\n",
            "Epoch 34/300, Loss: 0.47668057680130005\n",
            "Epoch 35/300, Loss: 0.4608298659324646\n",
            "Epoch 36/300, Loss: 0.46198770999908445\n",
            "Epoch 37/300, Loss: 0.46689853072166443\n",
            "Epoch 38/300, Loss: 0.4503865122795105\n",
            "Epoch 39/300, Loss: 0.44513198733329773\n",
            "Epoch 40/300, Loss: 0.449724817276001\n",
            "Epoch 41/300, Loss: 0.445487254858017\n",
            "Epoch 42/300, Loss: 0.4418277025222778\n",
            "Epoch 43/300, Loss: 0.4522801101207733\n",
            "Epoch 44/300, Loss: 0.4506918728351593\n",
            "Epoch 45/300, Loss: 0.44642007946968076\n",
            "Epoch 46/300, Loss: 0.4539019465446472\n",
            "Epoch 47/300, Loss: 0.44419655203819275\n",
            "Epoch 48/300, Loss: 0.42567925453186034\n",
            "Epoch 49/300, Loss: 0.43016589283943174\n",
            "Epoch 50/300, Loss: 0.4312431335449219\n",
            "Epoch 51/300, Loss: 0.434050714969635\n",
            "Epoch 52/300, Loss: 0.429555606842041\n",
            "Epoch 53/300, Loss: 0.42468941807746885\n",
            "Epoch 54/300, Loss: 0.41334605813026426\n",
            "Epoch 55/300, Loss: 0.4274028420448303\n",
            "Epoch 56/300, Loss: 0.42969350814819335\n",
            "Epoch 57/300, Loss: 0.4191850185394287\n",
            "Epoch 58/300, Loss: 0.43112024664878845\n",
            "Epoch 59/300, Loss: 0.43165422677993776\n",
            "Epoch 60/300, Loss: 0.40962759256362913\n",
            "Epoch 61/300, Loss: 0.4310027062892914\n",
            "Epoch 62/300, Loss: 0.43619816899299624\n",
            "Epoch 63/300, Loss: 0.4184259295463562\n",
            "Epoch 64/300, Loss: 0.4220054507255554\n",
            "Epoch 65/300, Loss: 0.4150398552417755\n",
            "Epoch 66/300, Loss: 0.41258043646812437\n",
            "Epoch 67/300, Loss: 0.420096218585968\n",
            "Epoch 68/300, Loss: 0.4239217579364777\n",
            "Epoch 69/300, Loss: 0.4016757905483246\n",
            "Epoch 70/300, Loss: 0.40568596720695493\n",
            "Epoch 71/300, Loss: 0.41411430239677427\n",
            "Epoch 72/300, Loss: 0.4026614189147949\n",
            "Epoch 73/300, Loss: 0.4078582227230072\n",
            "Epoch 74/300, Loss: 0.41933252215385436\n",
            "Epoch 75/300, Loss: 0.4005886346101761\n",
            "Epoch 76/300, Loss: 0.3984143078327179\n",
            "Epoch 77/300, Loss: 0.41061772108078004\n",
            "Epoch 78/300, Loss: 0.4050379037857056\n",
            "Epoch 79/300, Loss: 0.39865079522132874\n",
            "Epoch 80/300, Loss: 0.4059904634952545\n",
            "Epoch 81/300, Loss: 0.393815678358078\n",
            "Epoch 82/300, Loss: 0.40076603889465334\n",
            "Epoch 83/300, Loss: 0.4106013894081116\n",
            "Epoch 84/300, Loss: 0.4057802438735962\n",
            "Epoch 85/300, Loss: 0.38469685018062594\n",
            "Epoch 86/300, Loss: 0.4012770414352417\n",
            "Epoch 87/300, Loss: 0.39963074326515197\n",
            "Epoch 88/300, Loss: 0.3945873439311981\n",
            "Epoch 89/300, Loss: 0.3876865804195404\n",
            "Epoch 90/300, Loss: 0.4051667094230652\n",
            "Epoch 91/300, Loss: 0.3971272945404053\n",
            "Epoch 92/300, Loss: 0.4112873554229736\n",
            "Epoch 93/300, Loss: 0.3909895598888397\n",
            "Epoch 94/300, Loss: 0.3837803602218628\n",
            "Epoch 95/300, Loss: 0.3852812945842743\n",
            "Epoch 96/300, Loss: 0.38710862398147583\n",
            "Epoch 97/300, Loss: 0.3970411419868469\n",
            "Epoch 98/300, Loss: 0.3926412761211395\n",
            "Epoch 99/300, Loss: 0.37941695749759674\n",
            "Epoch 100/300, Loss: 0.39105443358421327\n",
            "Epoch 101/300, Loss: 0.39374730587005613\n",
            "Epoch 102/300, Loss: 0.412730747461319\n",
            "Epoch 103/300, Loss: 0.4127277672290802\n",
            "Epoch 104/300, Loss: 0.38801283240318296\n",
            "Epoch 105/300, Loss: 0.3891237795352936\n",
            "Epoch 106/300, Loss: 0.3826209604740143\n",
            "Epoch 107/300, Loss: 0.3864277362823486\n",
            "Epoch 108/300, Loss: 0.4062564432621002\n",
            "Epoch 109/300, Loss: 0.38367165327072145\n",
            "Epoch 110/300, Loss: 0.38001291155815126\n",
            "Epoch 111/300, Loss: 0.379118812084198\n",
            "Epoch 112/300, Loss: 0.38101264238357546\n",
            "Epoch 113/300, Loss: 0.38301404714584353\n",
            "Epoch 114/300, Loss: 0.37417869865894315\n",
            "Epoch 115/300, Loss: 0.3869536221027374\n",
            "Epoch 116/300, Loss: 0.3844373464584351\n",
            "Epoch 117/300, Loss: 0.3789424538612366\n",
            "Epoch 118/300, Loss: 0.38318212032318116\n",
            "Epoch 119/300, Loss: 0.3805109202861786\n",
            "Epoch 120/300, Loss: 0.3786524713039398\n",
            "Epoch 121/300, Loss: 0.394707065820694\n",
            "Epoch 122/300, Loss: 0.3751670777797699\n",
            "Epoch 123/300, Loss: 0.37404576539993284\n",
            "Epoch 124/300, Loss: 0.37958354949951173\n",
            "Epoch 125/300, Loss: 0.36461673080921175\n",
            "Epoch 126/300, Loss: 0.38668769001960757\n",
            "Epoch 127/300, Loss: 0.381585693359375\n",
            "Epoch 128/300, Loss: 0.37412890791893005\n",
            "Epoch 129/300, Loss: 0.3664358198642731\n",
            "Epoch 130/300, Loss: 0.3602445602416992\n",
            "Epoch 131/300, Loss: 0.3710605978965759\n",
            "Epoch 132/300, Loss: 0.36777461171150205\n",
            "Epoch 133/300, Loss: 0.36954686641693113\n",
            "Epoch 134/300, Loss: 0.378435343503952\n",
            "Epoch 135/300, Loss: 0.37293413281440735\n",
            "Epoch 136/300, Loss: 0.3901015639305115\n",
            "Epoch 137/300, Loss: 0.37031646966934206\n",
            "Epoch 138/300, Loss: 0.3594758599996567\n",
            "Epoch 139/300, Loss: 0.38275142312049865\n",
            "Epoch 140/300, Loss: 0.38292763829231263\n",
            "Epoch 141/300, Loss: 0.36666290163993837\n",
            "Epoch 142/300, Loss: 0.37936111688613894\n",
            "Epoch 143/300, Loss: 0.38230040669441223\n",
            "Epoch 144/300, Loss: 0.37142138481140136\n",
            "Epoch 145/300, Loss: 0.37708333432674407\n",
            "Epoch 146/300, Loss: 0.37695437073707583\n",
            "Epoch 147/300, Loss: 0.36544650197029116\n",
            "Epoch 148/300, Loss: 0.3753233373165131\n",
            "Epoch 149/300, Loss: 0.36749925315380094\n",
            "Epoch 150/300, Loss: 0.3611439347267151\n",
            "Epoch 151/300, Loss: 0.3716980814933777\n",
            "Epoch 152/300, Loss: 0.3882279396057129\n",
            "Epoch 153/300, Loss: 0.37238579988479614\n",
            "Epoch 154/300, Loss: 0.3572412610054016\n",
            "Epoch 155/300, Loss: 0.3718089282512665\n",
            "Epoch 156/300, Loss: 0.3911363422870636\n",
            "Epoch 157/300, Loss: 0.3649402916431427\n",
            "Epoch 158/300, Loss: 0.3700502872467041\n",
            "Epoch 159/300, Loss: 0.359174108505249\n",
            "Epoch 160/300, Loss: 0.3575007677078247\n",
            "Epoch 161/300, Loss: 0.3639536380767822\n",
            "Epoch 162/300, Loss: 0.3648755192756653\n",
            "Epoch 163/300, Loss: 0.36456281542778013\n",
            "Epoch 164/300, Loss: 0.37353198528289794\n",
            "Epoch 165/300, Loss: 0.3636955499649048\n",
            "Epoch 166/300, Loss: 0.355995899438858\n",
            "Epoch 167/300, Loss: 0.36879552602767945\n",
            "Epoch 168/300, Loss: 0.3544650197029114\n",
            "Epoch 169/300, Loss: 0.37058318853378297\n",
            "Epoch 170/300, Loss: 0.3626580059528351\n",
            "Epoch 171/300, Loss: 0.3534678161144257\n",
            "Epoch 172/300, Loss: 0.3519673466682434\n",
            "Epoch 173/300, Loss: 0.3477122843265533\n",
            "Epoch 174/300, Loss: 0.3528443992137909\n",
            "Epoch 175/300, Loss: 0.3698241412639618\n",
            "Epoch 176/300, Loss: 0.35744444131851194\n",
            "Epoch 177/300, Loss: 0.34400714635849\n",
            "Epoch 178/300, Loss: 0.3528009593486786\n",
            "Epoch 179/300, Loss: 0.344574773311615\n",
            "Epoch 180/300, Loss: 0.35491583347320554\n",
            "Epoch 181/300, Loss: 0.3531480014324188\n",
            "Epoch 182/300, Loss: 0.3726693481206894\n",
            "Epoch 183/300, Loss: 0.347123783826828\n",
            "Epoch 184/300, Loss: 0.36439948081970214\n",
            "Epoch 185/300, Loss: 0.3520939230918884\n",
            "Epoch 186/300, Loss: 0.3417358785867691\n",
            "Epoch 187/300, Loss: 0.349316281080246\n",
            "Epoch 188/300, Loss: 0.3565096139907837\n",
            "Epoch 189/300, Loss: 0.36151605248451235\n",
            "Epoch 190/300, Loss: 0.3550212860107422\n",
            "Epoch 191/300, Loss: 0.3504930794239044\n",
            "Epoch 192/300, Loss: 0.35855111479759216\n",
            "Epoch 193/300, Loss: 0.34450879096984866\n",
            "Epoch 194/300, Loss: 0.3580677926540375\n",
            "Epoch 195/300, Loss: 0.3602730453014374\n",
            "Epoch 196/300, Loss: 0.35183594226837156\n",
            "Epoch 197/300, Loss: 0.3486963927745819\n",
            "Epoch 198/300, Loss: 0.35140612721443176\n",
            "Epoch 199/300, Loss: 0.35294048190116883\n",
            "Epoch 200/300, Loss: 0.34266660511493685\n",
            "Epoch 201/300, Loss: 0.3540391981601715\n",
            "Epoch 202/300, Loss: 0.34174896478652955\n",
            "Epoch 203/300, Loss: 0.35194077491760256\n",
            "Epoch 204/300, Loss: 0.3413864016532898\n",
            "Epoch 205/300, Loss: 0.3513628602027893\n",
            "Epoch 206/300, Loss: 0.3524928689002991\n",
            "Epoch 207/300, Loss: 0.3534774899482727\n",
            "Epoch 208/300, Loss: 0.34268304109573366\n",
            "Epoch 209/300, Loss: 0.3502069115638733\n",
            "Epoch 210/300, Loss: 0.3627528250217438\n",
            "Epoch 211/300, Loss: 0.34117671847343445\n",
            "Epoch 212/300, Loss: 0.3498879075050354\n",
            "Epoch 213/300, Loss: 0.3366167306900024\n",
            "Epoch 214/300, Loss: 0.34281747937202456\n",
            "Epoch 215/300, Loss: 0.34933304190635683\n",
            "Epoch 216/300, Loss: 0.34123430252075193\n",
            "Epoch 217/300, Loss: 0.35297492146492004\n",
            "Epoch 218/300, Loss: 0.3367399960756302\n",
            "Epoch 219/300, Loss: 0.3536646395921707\n",
            "Epoch 220/300, Loss: 0.3424541771411896\n",
            "Epoch 221/300, Loss: 0.34679433703422546\n",
            "Epoch 222/300, Loss: 0.361205068230629\n",
            "Epoch 223/300, Loss: 0.34743990898132326\n",
            "Epoch 224/300, Loss: 0.33213080167770387\n",
            "Epoch 225/300, Loss: 0.3444828987121582\n",
            "Epoch 226/300, Loss: 0.33501169085502625\n",
            "Epoch 227/300, Loss: 0.34027611613273623\n",
            "Epoch 228/300, Loss: 0.3473096191883087\n",
            "Epoch 229/300, Loss: 0.35846898555755613\n",
            "Epoch 230/300, Loss: 0.356963574886322\n",
            "Epoch 231/300, Loss: 0.34926729202270507\n",
            "Epoch 232/300, Loss: 0.3349681556224823\n",
            "Epoch 233/300, Loss: 0.33467230200767517\n",
            "Epoch 234/300, Loss: 0.35171252489089966\n",
            "Epoch 235/300, Loss: 0.34829825162887573\n",
            "Epoch 236/300, Loss: 0.34437167048454287\n",
            "Epoch 237/300, Loss: 0.33900454044342043\n",
            "Epoch 238/300, Loss: 0.35124543905258176\n",
            "Epoch 239/300, Loss: 0.34468528628349304\n",
            "Epoch 240/300, Loss: 0.34448701739311216\n",
            "Epoch 241/300, Loss: 0.3454921722412109\n",
            "Epoch 242/300, Loss: 0.3542177140712738\n",
            "Epoch 243/300, Loss: 0.3444351464509964\n",
            "Epoch 244/300, Loss: 0.3404298901557922\n",
            "Epoch 245/300, Loss: 0.3377336025238037\n",
            "Epoch 246/300, Loss: 0.33907216787338257\n",
            "Epoch 247/300, Loss: 0.347583270072937\n",
            "Epoch 248/300, Loss: 0.3313855409622192\n",
            "Epoch 249/300, Loss: 0.3435806632041931\n",
            "Epoch 250/300, Loss: 0.33695623874664304\n",
            "Epoch 251/300, Loss: 0.3349969744682312\n",
            "Epoch 252/300, Loss: 0.34126917123794553\n",
            "Epoch 253/300, Loss: 0.3303902387619019\n",
            "Epoch 254/300, Loss: 0.33292446136474607\n",
            "Epoch 255/300, Loss: 0.32854286432266233\n",
            "Epoch 256/300, Loss: 0.3336857080459595\n",
            "Epoch 257/300, Loss: 0.33388417959213257\n",
            "Epoch 258/300, Loss: 0.33480049967765807\n",
            "Epoch 259/300, Loss: 0.33823519945144653\n",
            "Epoch 260/300, Loss: 0.3240247339010239\n",
            "Epoch 261/300, Loss: 0.32495729625225067\n",
            "Epoch 262/300, Loss: 0.3306361436843872\n",
            "Epoch 263/300, Loss: 0.3246838301420212\n",
            "Epoch 264/300, Loss: 0.3349910855293274\n",
            "Epoch 265/300, Loss: 0.3419027656316757\n",
            "Epoch 266/300, Loss: 0.33115684390068056\n",
            "Epoch 267/300, Loss: 0.3291250288486481\n",
            "Epoch 268/300, Loss: 0.32457211911678313\n",
            "Epoch 269/300, Loss: 0.32932519912719727\n",
            "Epoch 270/300, Loss: 0.34114799499511717\n",
            "Epoch 271/300, Loss: 0.3377557098865509\n",
            "Epoch 272/300, Loss: 0.33597477674484255\n",
            "Epoch 273/300, Loss: 0.3504847824573517\n",
            "Epoch 274/300, Loss: 0.31967535316944123\n",
            "Epoch 275/300, Loss: 0.3234542429447174\n",
            "Epoch 276/300, Loss: 0.33743167519569395\n",
            "Epoch 277/300, Loss: 0.33450546860694885\n",
            "Epoch 278/300, Loss: 0.33124326467514037\n",
            "Epoch 279/300, Loss: 0.33145257234573366\n",
            "Epoch 280/300, Loss: 0.32177711427211764\n",
            "Epoch 281/300, Loss: 0.3221507489681244\n",
            "Epoch 282/300, Loss: 0.32251486778259275\n",
            "Epoch 283/300, Loss: 0.3322946012020111\n",
            "Epoch 284/300, Loss: 0.3253259837627411\n",
            "Epoch 285/300, Loss: 0.324360716342926\n",
            "Epoch 286/300, Loss: 0.3258895814418793\n",
            "Epoch 287/300, Loss: 0.3334955990314484\n",
            "Epoch 288/300, Loss: 0.326341313123703\n",
            "Epoch 289/300, Loss: 0.32199293971061704\n",
            "Epoch 290/300, Loss: 0.3237387537956238\n",
            "Epoch 291/300, Loss: 0.31834588646888734\n",
            "Epoch 292/300, Loss: 0.32989675998687745\n",
            "Epoch 293/300, Loss: 0.33831933736801145\n",
            "Epoch 294/300, Loss: 0.3251424729824066\n",
            "Epoch 295/300, Loss: 0.32893341183662417\n",
            "Epoch 296/300, Loss: 0.3404043197631836\n",
            "Epoch 297/300, Loss: 0.32848952412605287\n",
            "Epoch 298/300, Loss: 0.3196733832359314\n",
            "Epoch 299/300, Loss: 0.32863108813762665\n",
            "Epoch 300/300, Loss: 0.32806926369667055\n",
            "Test Accuracy: 75.67567567567568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fua44rRLeKYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}